{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two step approach for QA-generation and evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is used to generate QA-pairs and get their evaluations according to the two-step approach described in the thesis. Three models are utlizied: Llama2 7b, Llama2 70b, and GPT-3.5. Thus, the code is run iteratively, by first using the get_gpt-function to generate questions and answers, and then get_llama where the model was firstly Llama2 70b and lastly Llama2 7b. This resulted in three outputted CSV-files: '2s_gpt.csv', '2s_llama2_70b.csv', and '2s_llama2_7b.csv' which are all attatched to the submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "import replicate\n",
    "import pandas as pd\n",
    "\n",
    "REPLICATE_API_TOKEN = getpass()\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = 'insert_api_key'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_llama(prompt):\n",
    "    max_retries = 3  # Maximum number of retries\n",
    "    retry_delay = 20  # Delay between retries in seconds\n",
    "    retries = 0\n",
    "\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            output = replicate.run(\n",
    "                \"meta/llama-2-7b-chat\",\n",
    "                input={\n",
    "                    \"prompt\": prompt,\n",
    "                    \"max_new_tokens\": 500,\n",
    "                    \"system_prompt\": \"\",\n",
    "                    \"Temperature\": 1\n",
    "                }\n",
    "            )\n",
    "\n",
    "            output = ''.join(output)\n",
    "            return output\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print(f\"Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "            retries += 1\n",
    "\n",
    "    print(\"Max retries reached. Unable to get response.\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'blogposts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0007\n",
      "0.0013\n",
      "0.002\n",
      "0.0026\n",
      "0.0033\n",
      "0.004\n",
      "0.0046\n",
      "0.0053\n",
      "0.006\n",
      "0.0073\n",
      "0.0079\n",
      "0.0086\n",
      "0.0093\n",
      "0.0099\n",
      "0.0106\n",
      "0.0113\n",
      "0.0119\n",
      "0.0126\n",
      "0.0139\n",
      "0.0146\n",
      "0.0152\n",
      "0.0159\n",
      "0.0165\n",
      "0.0172\n",
      "0.0179\n",
      "0.0185\n",
      "0.0192\n",
      "0.0205\n",
      "0.0212\n",
      "0.0218\n",
      "0.0225\n",
      "0.0232\n",
      "0.0238\n",
      "0.0245\n",
      "0.0251\n",
      "0.0258\n",
      "0.0271\n",
      "0.0278\n",
      "0.0285\n",
      "0.0291\n",
      "0.0298\n",
      "0.0304\n",
      "0.0311\n",
      "0.0318\n",
      "0.0324\n",
      "0.0338\n",
      "0.0344\n",
      "0.0351\n",
      "0.0357\n",
      "0.0364\n",
      "0.0371\n",
      "0.0377\n",
      "0.0384\n",
      "0.039\n",
      "0.0404\n",
      "0.041\n",
      "0.0417\n",
      "0.0424\n",
      "0.043\n",
      "0.0437\n",
      "0.0443\n",
      "0.045\n",
      "0.0457\n",
      "0.047\n",
      "0.0477\n",
      "0.0483\n",
      "0.049\n",
      "0.0496\n",
      "0.0503\n",
      "0.051\n",
      "0.0516\n",
      "0.0523\n",
      "0.0536\n",
      "0.0543\n",
      "0.0549\n",
      "0.0556\n",
      "0.0563\n",
      "0.0569\n",
      "0.0576\n",
      "0.0582\n",
      "0.0589\n",
      "0.0602\n",
      "0.0609\n",
      "0.0615\n",
      "0.0622\n",
      "0.0629\n",
      "0.0635\n",
      "0.0642\n",
      "0.0649\n",
      "0.0655\n",
      "0.0668\n",
      "0.0675\n",
      "0.0682\n",
      "0.0688\n",
      "0.0695\n",
      "0.0702\n",
      "0.0708\n",
      "0.0715\n",
      "0.0721\n",
      "0.0735\n",
      "0.0741\n",
      "0.0748\n",
      "0.0754\n",
      "0.0761\n",
      "0.0768\n",
      "0.0774\n",
      "0.0781\n",
      "0.0788\n",
      "0.0801\n",
      "0.0807\n",
      "0.0814\n",
      "0.0821\n",
      "0.0827\n",
      "0.0834\n",
      "0.0841\n",
      "0.0847\n",
      "0.0854\n",
      "0.0867\n",
      "0.0874\n",
      "0.088\n",
      "0.0887\n",
      "0.0893\n",
      "0.09\n",
      "0.0907\n",
      "0.0913\n",
      "0.092\n",
      "0.0933\n",
      "0.094\n",
      "0.0946\n",
      "0.0953\n",
      "0.096\n",
      "0.0966\n",
      "0.0973\n",
      "0.0979\n",
      "0.0986\n",
      "0.0999\n",
      "0.1006\n",
      "0.1013\n",
      "0.1019\n",
      "0.1026\n",
      "0.1032\n",
      "0.1039\n",
      "0.1046\n",
      "0.1052\n",
      "0.1066\n",
      "0.1072\n",
      "0.1079\n",
      "0.1085\n",
      "0.1092\n",
      "0.1099\n",
      "0.1105\n",
      "0.1112\n",
      "0.1118\n",
      "0.1132\n",
      "0.1138\n",
      "0.1145\n",
      "0.1152\n",
      "0.1158\n",
      "0.1165\n",
      "0.1171\n",
      "0.1178\n",
      "0.1185\n",
      "0.1198\n",
      "0.1205\n",
      "0.1211\n",
      "0.1218\n",
      "0.1224\n",
      "0.1231\n",
      "0.1238\n",
      "0.1244\n",
      "0.1251\n",
      "0.1264\n",
      "0.1271\n",
      "0.1277\n",
      "0.1284\n",
      "0.1291\n",
      "0.1297\n",
      "0.1304\n",
      "0.131\n",
      "0.1317\n",
      "0.133\n",
      "0.1337\n",
      "0.1343\n",
      "0.135\n",
      "0.1357\n",
      "0.1363\n",
      "0.137\n",
      "0.1377\n",
      "0.1383\n",
      "0.1396\n",
      "0.1403\n",
      "0.141\n",
      "0.1416\n",
      "0.1423\n",
      "0.143\n",
      "0.1436\n",
      "0.1443\n",
      "0.1449\n",
      "0.1463\n",
      "0.1469\n",
      "0.1476\n",
      "0.1482\n",
      "0.1489\n",
      "0.1496\n",
      "0.1502\n",
      "0.1509\n",
      "0.1516\n",
      "0.1529\n",
      "0.1535\n",
      "0.1542\n",
      "0.1549\n",
      "0.1555\n",
      "0.1562\n",
      "0.1568\n",
      "0.1575\n",
      "0.1582\n",
      "0.1595\n",
      "0.1602\n",
      "0.1608\n",
      "0.1615\n",
      "0.1621\n",
      "0.1628\n",
      "0.1635\n",
      "0.1641\n",
      "0.1648\n",
      "0.1661\n",
      "0.1668\n",
      "0.1674\n",
      "0.1681\n",
      "0.1688\n",
      "0.1694\n",
      "0.1701\n",
      "0.1707\n",
      "0.1714\n",
      "0.1727\n",
      "0.1734\n",
      "0.1741\n",
      "0.1747\n",
      "0.1754\n",
      "0.176\n",
      "0.1767\n",
      "0.1774\n",
      "0.178\n",
      "0.1794\n",
      "0.18\n",
      "0.1807\n",
      "0.1813\n",
      "0.182\n",
      "0.1827\n",
      "0.1833\n",
      "0.184\n",
      "0.1846\n",
      "0.186\n",
      "0.1866\n",
      "0.1873\n",
      "0.188\n",
      "0.1886\n",
      "0.1893\n",
      "0.1899\n",
      "0.1906\n",
      "0.1913\n",
      "0.1926\n",
      "0.1932\n",
      "0.1939\n",
      "0.1946\n",
      "0.1952\n",
      "0.1959\n",
      "0.1966\n",
      "0.1972\n",
      "0.1979\n",
      "0.1992\n",
      "0.1999\n",
      "0.2005\n",
      "0.2012\n",
      "0.2019\n",
      "0.2025\n",
      "0.2032\n",
      "0.2038\n",
      "0.2045\n",
      "0.2058\n",
      "0.2065\n",
      "0.2071\n",
      "0.2078\n",
      "0.2085\n",
      "0.2091\n",
      "0.2098\n",
      "0.2105\n",
      "0.2111\n",
      "0.2124\n",
      "0.2131\n",
      "0.2138\n",
      "0.2144\n",
      "0.2151\n",
      "0.2158\n",
      "0.2164\n",
      "0.2171\n",
      "0.2177\n",
      "0.2191\n",
      "0.2197\n",
      "0.2204\n",
      "0.221\n",
      "0.2217\n",
      "0.2224\n",
      "0.223\n",
      "0.2237\n",
      "0.2244\n",
      "0.2257\n",
      "0.2263\n",
      "0.227\n",
      "0.2277\n",
      "0.2283\n",
      "0.229\n",
      "0.2296\n",
      "0.2303\n",
      "0.231\n",
      "0.2323\n",
      "0.233\n",
      "0.2336\n",
      "0.2343\n",
      "0.2349\n",
      "0.2356\n",
      "0.2363\n",
      "0.2369\n",
      "0.2376\n",
      "0.2389\n",
      "0.2396\n",
      "0.2402\n",
      "0.2409\n",
      "0.2416\n",
      "0.2422\n",
      "0.2429\n",
      "0.2435\n",
      "0.2442\n",
      "0.2455\n",
      "0.2462\n",
      "0.2469\n",
      "0.2475\n",
      "0.2482\n",
      "0.2488\n",
      "0.2495\n",
      "0.2502\n",
      "0.2508\n",
      "0.2522\n",
      "0.2528\n",
      "0.2535\n",
      "0.2541\n",
      "0.2548\n",
      "0.2555\n",
      "0.2561\n",
      "0.2568\n",
      "0.2574\n",
      "0.2588\n",
      "0.2594\n",
      "0.2601\n",
      "0.2608\n",
      "0.2614\n",
      "0.2621\n",
      "0.2627\n",
      "0.2634\n",
      "0.2641\n",
      "0.2654\n",
      "0.266\n",
      "0.2667\n",
      "0.2674\n",
      "0.268\n",
      "0.2687\n",
      "0.2694\n",
      "0.27\n",
      "0.2707\n",
      "0.272\n",
      "0.2727\n",
      "0.2733\n",
      "0.274\n",
      "0.2747\n",
      "0.2753\n",
      "0.276\n",
      "0.2766\n",
      "0.2773\n",
      "0.2786\n",
      "0.2793\n",
      "0.2799\n",
      "0.2806\n",
      "0.2813\n",
      "0.2819\n",
      "0.2826\n",
      "0.2833\n",
      "0.2839\n",
      "0.2852\n",
      "0.2859\n",
      "0.2866\n",
      "0.2872\n",
      "0.2879\n",
      "0.2886\n",
      "0.2892\n",
      "0.2899\n",
      "0.2905\n",
      "0.2919\n",
      "0.2925\n",
      "0.2932\n",
      "0.2938\n",
      "0.2945\n",
      "0.2952\n",
      "0.2958\n",
      "0.2965\n",
      "0.2972\n",
      "0.2985\n",
      "0.2991\n",
      "0.2998\n",
      "0.3005\n",
      "0.3011\n",
      "0.3018\n",
      "0.3024\n",
      "0.3031\n",
      "0.3038\n",
      "0.3051\n",
      "0.3058\n",
      "0.3064\n",
      "0.3071\n",
      "0.3077\n",
      "0.3084\n",
      "0.3091\n",
      "0.3097\n",
      "0.3104\n",
      "0.3117\n",
      "0.3124\n",
      "0.313\n",
      "0.3137\n",
      "0.3144\n",
      "0.315\n",
      "0.3157\n",
      "0.3163\n",
      "0.317\n",
      "0.3183\n",
      "0.319\n",
      "0.3197\n",
      "0.3203\n",
      "0.321\n",
      "0.3216\n",
      "0.3223\n",
      "0.323\n",
      "0.3236\n",
      "0.325\n",
      "0.3256\n",
      "0.3263\n",
      "0.3269\n",
      "0.3276\n",
      "0.3283\n",
      "0.3289\n",
      "0.3296\n",
      "0.3302\n",
      "0.3316\n",
      "0.3322\n",
      "0.3329\n",
      "0.3336\n",
      "0.3342\n",
      "0.3349\n",
      "0.3355\n",
      "0.3362\n",
      "0.3369\n",
      "0.3382\n",
      "0.3388\n",
      "0.3395\n",
      "0.3402\n",
      "0.3408\n",
      "0.3415\n",
      "0.3422\n",
      "0.3428\n",
      "0.3435\n",
      "0.3448\n",
      "0.3455\n",
      "0.3461\n",
      "0.3468\n",
      "0.3475\n",
      "0.3481\n",
      "0.3488\n",
      "0.3494\n",
      "0.3501\n",
      "0.3514\n",
      "0.3521\n",
      "0.3527\n",
      "0.3534\n",
      "0.3541\n",
      "0.3547\n",
      "0.3554\n",
      "0.3561\n",
      "0.3567\n",
      "0.358\n",
      "0.3587\n",
      "0.3594\n",
      "0.36\n",
      "0.3607\n",
      "0.3614\n",
      "0.362\n",
      "0.3627\n",
      "0.3633\n",
      "0.3647\n",
      "0.3653\n",
      "0.366\n",
      "0.3666\n",
      "0.3673\n",
      "0.368\n",
      "0.3686\n",
      "0.3693\n",
      "0.37\n",
      "0.3713\n",
      "0.3719\n",
      "0.3726\n",
      "0.3733\n",
      "0.3739\n",
      "0.3746\n",
      "0.3752\n",
      "0.3759\n",
      "0.3766\n",
      "0.3779\n",
      "0.3786\n",
      "0.3792\n",
      "0.3799\n",
      "0.3805\n",
      "0.3812\n",
      "0.3819\n",
      "0.3825\n",
      "0.3832\n",
      "0.3845\n",
      "0.3852\n",
      "0.3858\n",
      "0.3865\n",
      "0.3872\n",
      "0.3878\n",
      "0.3885\n",
      "0.3891\n",
      "0.3898\n",
      "0.3911\n",
      "0.3918\n",
      "0.3925\n",
      "0.3931\n",
      "0.3938\n",
      "0.3944\n",
      "0.3951\n",
      "0.3958\n",
      "0.3964\n",
      "0.3977\n",
      "0.3984\n",
      "0.3991\n",
      "0.3997\n",
      "0.4004\n",
      "0.4011\n",
      "0.4017\n",
      "0.4024\n",
      "0.403\n",
      "0.4044\n",
      "0.405\n",
      "0.4057\n",
      "0.4064\n",
      "0.407\n",
      "0.4077\n",
      "0.4083\n",
      "0.409\n",
      "0.4097\n",
      "0.411\n",
      "0.4116\n",
      "0.4123\n",
      "0.413\n",
      "0.4136\n",
      "0.4143\n",
      "0.415\n",
      "0.4156\n",
      "0.4163\n",
      "0.4176\n",
      "0.4183\n",
      "0.4189\n",
      "0.4196\n",
      "0.4203\n",
      "0.4209\n",
      "0.4216\n",
      "0.4222\n",
      "0.4229\n",
      "0.4242\n",
      "0.4249\n",
      "0.4255\n",
      "0.4262\n",
      "0.4269\n",
      "0.4275\n",
      "0.4282\n",
      "0.4289\n",
      "0.4295\n",
      "0.4308\n",
      "0.4315\n",
      "0.4322\n",
      "0.4328\n",
      "0.4335\n",
      "0.4341\n",
      "0.4348\n",
      "0.4355\n",
      "0.4361\n",
      "0.4375\n",
      "0.4381\n",
      "0.4388\n",
      "0.4394\n",
      "0.4401\n",
      "0.4408\n",
      "0.4414\n",
      "0.4421\n",
      "0.4428\n",
      "0.4441\n",
      "0.4447\n",
      "0.4454\n",
      "0.4461\n",
      "0.4467\n",
      "0.4474\n",
      "0.448\n",
      "0.4487\n",
      "0.4494\n",
      "0.4507\n",
      "0.4514\n",
      "0.452\n",
      "0.4527\n",
      "0.4533\n",
      "0.454\n",
      "0.4547\n",
      "0.4553\n",
      "0.456\n",
      "0.4573\n",
      "0.458\n",
      "0.4586\n",
      "0.4593\n",
      "0.46\n",
      "0.4606\n",
      "0.4613\n",
      "0.4619\n",
      "0.4626\n",
      "0.4639\n",
      "0.4646\n",
      "0.4653\n",
      "0.4659\n",
      "0.4666\n",
      "0.4672\n",
      "0.4679\n",
      "0.4686\n",
      "0.4692\n",
      "0.4705\n",
      "0.4712\n",
      "0.4719\n",
      "0.4725\n",
      "0.4732\n",
      "0.4739\n",
      "0.4745\n",
      "0.4752\n",
      "0.4758\n",
      "0.4772\n",
      "0.4778\n",
      "0.4785\n",
      "0.4792\n",
      "0.4798\n",
      "0.4805\n",
      "0.4811\n",
      "0.4818\n",
      "0.4825\n",
      "0.4838\n",
      "0.4844\n",
      "0.4851\n",
      "0.4858\n",
      "0.4864\n",
      "0.4871\n",
      "0.4878\n",
      "0.4884\n",
      "0.4891\n",
      "0.4904\n",
      "0.4911\n",
      "0.4917\n",
      "0.4924\n",
      "0.4931\n",
      "0.4937\n",
      "0.4944\n",
      "0.495\n",
      "0.4957\n",
      "0.497\n",
      "0.4977\n",
      "0.4983\n",
      "0.499\n",
      "0.4997\n",
      "0.5003\n",
      "0.501\n",
      "0.5017\n",
      "0.5023\n",
      "0.5036\n",
      "0.5043\n",
      "0.505\n",
      "0.5056\n",
      "0.5063\n",
      "0.5069\n",
      "0.5076\n",
      "0.5083\n",
      "0.5089\n",
      "0.5103\n",
      "0.5109\n",
      "0.5116\n",
      "0.5122\n",
      "0.5129\n",
      "0.5136\n",
      "0.5142\n",
      "0.5149\n",
      "0.5156\n",
      "0.5169\n",
      "0.5175\n",
      "0.5182\n",
      "0.5189\n",
      "0.5195\n",
      "0.5202\n",
      "0.5208\n",
      "0.5215\n",
      "0.5222\n",
      "0.5235\n",
      "0.5242\n",
      "0.5248\n",
      "0.5255\n",
      "0.5261\n",
      "0.5268\n",
      "0.5275\n",
      "0.5281\n",
      "0.5288\n",
      "0.5301\n",
      "0.5308\n",
      "0.5314\n",
      "0.5321\n",
      "0.5328\n",
      "0.5334\n",
      "0.5341\n",
      "0.5347\n",
      "0.5354\n",
      "0.5367\n",
      "0.5374\n",
      "0.5381\n",
      "0.5387\n",
      "0.5394\n",
      "0.54\n",
      "0.5407\n",
      "0.5414\n",
      "0.542\n",
      "0.5433\n",
      "0.544\n",
      "0.5447\n",
      "0.5453\n",
      "0.546\n",
      "0.5467\n",
      "0.5473\n",
      "0.548\n",
      "0.5486\n",
      "0.55\n",
      "0.5506\n",
      "0.5513\n",
      "0.552\n",
      "0.5526\n",
      "0.5533\n",
      "0.5539\n",
      "0.5546\n",
      "0.5553\n",
      "0.5566\n",
      "0.5572\n",
      "0.5579\n",
      "0.5586\n",
      "0.5592\n",
      "0.5599\n",
      "0.5606\n",
      "0.5612\n",
      "0.5619\n",
      "0.5632\n",
      "0.5639\n",
      "0.5645\n",
      "0.5652\n",
      "0.5659\n",
      "0.5665\n",
      "0.5672\n",
      "0.5678\n",
      "0.5685\n",
      "0.5698\n",
      "0.5705\n",
      "0.5711\n",
      "0.5718\n",
      "0.5725\n",
      "0.5731\n",
      "0.5738\n",
      "0.5745\n",
      "0.5751\n",
      "0.5764\n",
      "0.5771\n",
      "0.5778\n",
      "0.5784\n",
      "0.5791\n",
      "0.5797\n",
      "0.5804\n",
      "0.5811\n",
      "0.5817\n",
      "0.5831\n",
      "0.5837\n",
      "0.5844\n",
      "0.585\n",
      "0.5857\n",
      "0.5864\n",
      "0.587\n",
      "0.5877\n",
      "0.5884\n",
      "0.5897\n",
      "0.5903\n",
      "0.591\n",
      "0.5917\n",
      "0.5923\n",
      "0.593\n",
      "0.5936\n",
      "0.5943\n",
      "0.595\n",
      "0.5963\n",
      "0.597\n",
      "0.5976\n",
      "0.5983\n",
      "0.5989\n",
      "0.5996\n",
      "0.6003\n",
      "0.6009\n",
      "0.6016\n",
      "0.6029\n",
      "0.6036\n",
      "0.6042\n",
      "0.6049\n",
      "0.6056\n",
      "0.6062\n",
      "0.6069\n",
      "0.6075\n",
      "0.6082\n",
      "0.6095\n",
      "0.6102\n",
      "0.6109\n",
      "0.6115\n",
      "0.6122\n",
      "0.6128\n",
      "0.6135\n",
      "0.6142\n",
      "0.6148\n",
      "0.6161\n",
      "0.6168\n",
      "0.6175\n",
      "0.6181\n",
      "0.6188\n",
      "0.6195\n",
      "0.6201\n",
      "0.6208\n",
      "0.6214\n",
      "0.6228\n",
      "0.6234\n",
      "0.6241\n",
      "0.6248\n",
      "0.6254\n",
      "0.6261\n",
      "0.6267\n",
      "0.6274\n",
      "0.6281\n",
      "0.6294\n",
      "0.63\n",
      "0.6307\n",
      "0.6314\n",
      "0.632\n",
      "0.6327\n",
      "0.6334\n",
      "0.634\n",
      "0.6347\n",
      "0.636\n",
      "0.6367\n",
      "0.6373\n",
      "0.638\n",
      "0.6386\n",
      "0.6393\n",
      "0.64\n",
      "0.6406\n",
      "0.6413\n",
      "0.6426\n",
      "0.6433\n",
      "0.6439\n",
      "0.6446\n",
      "0.6453\n",
      "0.6459\n",
      "0.6466\n",
      "0.6473\n",
      "0.6479\n",
      "0.6492\n",
      "0.6499\n",
      "0.6506\n",
      "0.6512\n",
      "0.6519\n",
      "0.6525\n",
      "0.6532\n",
      "0.6539\n",
      "0.6545\n",
      "0.6559\n",
      "0.6565\n",
      "0.6572\n",
      "0.6578\n",
      "0.6585\n",
      "0.6592\n",
      "0.6598\n",
      "0.6605\n",
      "0.6612\n",
      "0.6625\n",
      "0.6631\n",
      "0.6638\n",
      "0.6645\n",
      "0.6651\n",
      "0.6658\n",
      "0.6664\n",
      "0.6671\n",
      "0.6678\n",
      "0.6691\n",
      "0.6698\n",
      "0.6704\n",
      "0.6711\n",
      "0.6717\n",
      "0.6724\n",
      "0.6731\n",
      "0.6737\n",
      "0.6744\n",
      "0.6757\n",
      "0.6764\n",
      "0.677\n",
      "0.6777\n",
      "0.6784\n",
      "0.679\n",
      "0.6797\n",
      "0.6803\n",
      "0.681\n",
      "0.6823\n",
      "0.683\n",
      "0.6837\n",
      "0.6843\n",
      "0.685\n",
      "0.6856\n",
      "0.6863\n",
      "0.687\n",
      "0.6876\n",
      "0.6889\n",
      "0.6896\n",
      "0.6903\n",
      "0.6909\n",
      "0.6916\n",
      "0.6923\n",
      "0.6929\n",
      "0.6936\n",
      "0.6942\n",
      "0.6956\n",
      "0.6962\n",
      "0.6969\n",
      "0.6976\n",
      "0.6982\n",
      "0.6989\n",
      "0.6995\n",
      "0.7002\n",
      "0.7009\n",
      "0.7022\n",
      "0.7028\n",
      "0.7035\n",
      "0.7042\n",
      "0.7048\n",
      "0.7055\n",
      "0.7062\n",
      "0.7068\n",
      "0.7075\n",
      "0.7088\n",
      "0.7095\n",
      "0.7101\n",
      "0.7108\n",
      "0.7114\n",
      "0.7121\n",
      "0.7128\n",
      "0.7134\n",
      "0.7141\n",
      "0.7154\n",
      "0.7161\n",
      "0.7167\n",
      "0.7174\n",
      "0.7181\n",
      "0.7187\n",
      "0.7194\n",
      "0.7201\n",
      "0.7207\n",
      "0.722\n",
      "0.7227\n",
      "0.7234\n",
      "0.724\n",
      "0.7247\n",
      "0.7253\n",
      "0.726\n",
      "0.7267\n",
      "0.7273\n",
      "0.7287\n",
      "0.7293\n",
      "0.73\n",
      "0.7306\n",
      "0.7313\n",
      "0.732\n",
      "0.7326\n",
      "0.7333\n",
      "0.734\n",
      "0.7353\n",
      "0.7359\n",
      "0.7366\n",
      "0.7373\n",
      "0.7379\n",
      "0.7386\n",
      "0.7392\n",
      "0.7399\n",
      "0.7406\n",
      "0.7419\n",
      "0.7426\n",
      "0.7432\n",
      "0.7439\n",
      "0.7445\n",
      "0.7452\n",
      "0.7459\n",
      "0.7465\n",
      "0.7472\n",
      "0.7485\n",
      "0.7492\n",
      "0.7498\n",
      "0.7505\n",
      "0.7512\n",
      "0.7518\n",
      "0.7525\n",
      "0.7531\n",
      "0.7538\n",
      "0.7551\n",
      "0.7558\n",
      "0.7565\n",
      "0.7571\n",
      "0.7578\n",
      "0.7584\n",
      "0.7591\n",
      "0.7598\n",
      "0.7604\n",
      "0.7617\n",
      "0.7624\n",
      "0.7631\n",
      "0.7637\n",
      "0.7644\n",
      "0.7651\n",
      "0.7657\n",
      "0.7664\n",
      "0.767\n",
      "0.7684\n",
      "0.769\n",
      "0.7697\n",
      "0.7704\n",
      "0.771\n",
      "0.7717\n",
      "0.7723\n",
      "0.773\n",
      "0.7737\n",
      "0.775\n",
      "0.7756\n",
      "0.7763\n",
      "0.777\n",
      "0.7776\n",
      "0.7783\n",
      "0.779\n",
      "0.7796\n",
      "0.7803\n",
      "0.7816\n",
      "0.7823\n",
      "0.7829\n",
      "0.7836\n",
      "0.7842\n",
      "0.7849\n",
      "0.7856\n",
      "0.7862\n",
      "0.7869\n",
      "0.7882\n",
      "0.7889\n",
      "0.7895\n",
      "0.7902\n",
      "0.7909\n",
      "0.7915\n",
      "0.7922\n",
      "0.7929\n",
      "0.7935\n",
      "0.7948\n",
      "0.7955\n",
      "0.7962\n",
      "0.7968\n",
      "0.7975\n",
      "0.7981\n",
      "0.7988\n",
      "0.7995\n",
      "0.8001\n",
      "0.8015\n",
      "0.8021\n",
      "0.8028\n",
      "0.8034\n",
      "0.8041\n",
      "0.8048\n",
      "0.8054\n",
      "0.8061\n",
      "0.8068\n",
      "0.8081\n",
      "0.8087\n",
      "0.8094\n",
      "0.8101\n",
      "0.8107\n",
      "0.8114\n",
      "0.812\n",
      "0.8127\n",
      "0.8134\n",
      "0.8147\n",
      "0.8154\n",
      "0.816\n",
      "0.8167\n",
      "An error occurred: Prediction interrupted; please retry (code: PA)\n",
      "Retrying in 20 seconds...\n",
      "0.8173\n",
      "0.818\n",
      "0.8187\n",
      "0.8193\n",
      "0.82\n",
      "0.8213\n",
      "0.822\n",
      "0.8226\n",
      "0.8233\n",
      "0.824\n",
      "0.8246\n",
      "0.8253\n",
      "0.8259\n",
      "0.8266\n",
      "0.8279\n",
      "0.8286\n",
      "0.8293\n",
      "0.8299\n",
      "0.8306\n",
      "0.8312\n",
      "0.8319\n",
      "0.8326\n",
      "0.8332\n",
      "0.8345\n",
      "0.8352\n",
      "0.8359\n",
      "0.8365\n",
      "0.8372\n",
      "0.8379\n",
      "0.8385\n",
      "0.8392\n",
      "0.8398\n",
      "0.8412\n",
      "0.8418\n",
      "0.8425\n",
      "0.8432\n",
      "0.8438\n",
      "0.8445\n",
      "0.8451\n",
      "0.8458\n",
      "0.8465\n",
      "0.8478\n",
      "0.8484\n",
      "0.8491\n",
      "0.8498\n",
      "0.8504\n",
      "0.8511\n",
      "0.8518\n",
      "0.8524\n",
      "0.8531\n",
      "0.8544\n",
      "0.8551\n",
      "0.8557\n",
      "0.8564\n",
      "0.857\n",
      "0.8577\n",
      "0.8584\n",
      "0.859\n",
      "0.8597\n",
      "0.861\n",
      "0.8617\n",
      "0.8623\n",
      "0.863\n",
      "0.8637\n",
      "0.8643\n",
      "0.865\n",
      "0.8657\n",
      "0.8663\n",
      "0.8676\n",
      "0.8683\n",
      "0.869\n",
      "0.8696\n",
      "0.8703\n",
      "0.8709\n",
      "0.8716\n",
      "0.8723\n",
      "0.8729\n",
      "0.8743\n",
      "0.8749\n",
      "0.8756\n",
      "0.8762\n",
      "0.8769\n",
      "0.8776\n",
      "0.8782\n",
      "0.8789\n",
      "0.8795\n",
      "0.8809\n",
      "0.8815\n",
      "0.8822\n",
      "0.8829\n",
      "0.8835\n",
      "0.8842\n",
      "0.8848\n",
      "0.8855\n",
      "0.8862\n",
      "0.8875\n",
      "0.8882\n",
      "0.8888\n",
      "0.8895\n",
      "0.8901\n",
      "0.8908\n",
      "0.8915\n",
      "0.8921\n",
      "0.8928\n",
      "0.8941\n",
      "0.8948\n",
      "0.8954\n",
      "0.8961\n",
      "0.8968\n",
      "0.8974\n",
      "0.8981\n",
      "0.8987\n",
      "0.8994\n",
      "0.9007\n",
      "0.9014\n",
      "0.9021\n",
      "0.9027\n",
      "0.9034\n",
      "0.904\n",
      "0.9047\n",
      "0.9054\n",
      "0.906\n",
      "0.9073\n",
      "0.908\n",
      "0.9087\n",
      "0.9093\n",
      "0.91\n",
      "0.9107\n",
      "0.9113\n",
      "0.912\n",
      "0.9126\n",
      "0.914\n",
      "0.9146\n",
      "0.9153\n",
      "0.9159\n",
      "0.9166\n",
      "0.9173\n",
      "0.9179\n",
      "0.9186\n",
      "0.9193\n",
      "0.9206\n",
      "0.9212\n",
      "0.9219\n",
      "0.9226\n",
      "0.9232\n",
      "0.9239\n",
      "0.9246\n",
      "0.9252\n",
      "0.9259\n",
      "0.9272\n",
      "0.9279\n",
      "0.9285\n",
      "0.9292\n",
      "0.9298\n",
      "0.9305\n",
      "0.9312\n",
      "0.9318\n",
      "0.9325\n",
      "0.9338\n",
      "0.9345\n",
      "0.9351\n",
      "0.9358\n",
      "0.9365\n",
      "0.9371\n",
      "0.9378\n",
      "0.9385\n",
      "0.9391\n",
      "0.9404\n",
      "0.9411\n",
      "0.9418\n",
      "0.9424\n",
      "0.9431\n",
      "0.9437\n",
      "0.9444\n",
      "0.9451\n",
      "0.9457\n",
      "0.9471\n",
      "0.9477\n",
      "0.9484\n",
      "0.949\n",
      "0.9497\n",
      "0.9504\n",
      "0.951\n",
      "0.9517\n",
      "0.9523\n",
      "0.9537\n",
      "0.9543\n",
      "0.955\n",
      "0.9557\n",
      "0.9563\n",
      "0.957\n",
      "0.9576\n",
      "0.9583\n",
      "0.959\n",
      "0.9603\n",
      "0.961\n",
      "0.9616\n",
      "0.9623\n",
      "0.9629\n",
      "0.9636\n",
      "0.9643\n",
      "0.9649\n",
      "0.9656\n",
      "0.9669\n",
      "0.9676\n",
      "0.9682\n",
      "0.9689\n",
      "0.9696\n",
      "0.9702\n",
      "0.9709\n",
      "0.9715\n",
      "0.9722\n",
      "0.9735\n",
      "0.9742\n",
      "0.9749\n",
      "0.9755\n",
      "0.9762\n",
      "0.9768\n",
      "0.9775\n",
      "0.9782\n",
      "0.9788\n",
      "0.9801\n",
      "0.9808\n",
      "0.9815\n",
      "0.9821\n",
      "0.9828\n",
      "0.9835\n",
      "0.9841\n",
      "0.9848\n",
      "0.9854\n",
      "0.9868\n",
      "0.9874\n",
      "0.9881\n",
      "0.9887\n",
      "0.9894\n",
      "0.9901\n",
      "0.9907\n",
      "0.9914\n",
      "0.9921\n",
      "0.9934\n",
      "0.994\n",
      "0.9947\n",
      "0.9954\n",
      "0.996\n",
      "0.9967\n",
      "0.9974\n",
      "0.998\n",
      "0.9987\n"
     ]
    }
   ],
   "source": [
    "questions = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    prompt = f\"\"\" \n",
    "              This is an example of a blogpost from Bang and Olufsen's forum in JSON format:\n",
    "\n",
    "              {row['text']}\n",
    "    \n",
    "              Read the post, act as a Bang&Olufsen product expert and form a single question mentioning the products or problems, if any, to capture the most important problem of the post: \n",
    "    \n",
    "            There are some rules:\n",
    "           - Do not mention user names\n",
    "           - Answer only with a single question\n",
    "           \"\"\"\n",
    "\n",
    "    question = get_llama(prompt)\n",
    "    questions.append(question)\n",
    "    if index % 10 or index < 5:\n",
    "        #print(question)\n",
    "        print(round(index / len(df), 4))\n",
    "\n",
    "df['questions'] = questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the last model, llama2 7b, the some outputs included unnecessary citation signs. This code removes them \n",
    "import re\n",
    "cleaned_questions = [] \n",
    "for index, row in df.iterrows():\n",
    "    string = row['questions']\n",
    "    match = re.search('\\n+(.*)', string)\n",
    "    if match:\n",
    "        cleaned_questions.append(match.group(1).strip('\"'))\n",
    "    else:\n",
    "        cleaned_questions.append(string)\n",
    "\n",
    "df['cleaned_questions'] = cleaned_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define get_gpt\n",
    "def get_gpt(prompt):\n",
    "    openai.api_key = 'insert_api_key'\n",
    "\n",
    "    attempts = 0\n",
    "    max_attempts = 5  # Max attempts before giving up\n",
    "    backoff_time = 1  # Initial backoff time in seconds\n",
    "\n",
    "    while attempts < max_attempts:\n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                max_tokens=2000,\n",
    "                temperature=1)\n",
    "            resp = completion.choices[0].message[\"content\"]\n",
    "            return resp\n",
    "\n",
    "        except openai.error.APIError as e:\n",
    "            # Handle API-specific errors here\n",
    "            print(f\"OpenAI API returned an API Error: {e}\")\n",
    "            break  # Stop after an API error\n",
    "        except Exception as e:\n",
    "            # This catches any other exceptions\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            attempts += 1\n",
    "            time.sleep(backoff_time)\n",
    "            backoff_time *= 2  # Exponential backoff\n",
    "\n",
    "    # Return a default response or raise an error after max attempts\n",
    "    raise Exception(\"Failed to get a response from OpenAI API after multiple attempts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast \n",
    "import openai\n",
    "\n",
    "\n",
    "def evaluate_question(row):\n",
    "    post, question = row['text'], row['cleaned_questions']\n",
    "    example_dict = {'Relevance': 1, 'Coverage': 4, 'Details': 2, 'Fluency': 3}\n",
    "    \n",
    "\n",
    "    prompt = f\"\"\" \n",
    "\n",
    "You will be given one question based on a blogpost.\n",
    "\n",
    "Your task is to rate the question on three metrics.\n",
    "\n",
    "Please make sure you read and understand these instructions carefully. \n",
    "\n",
    "Instructions:\n",
    "1. Read the question the blogpost carefully.\n",
    "2. Read the blogpost and identify the issue the article.\n",
    "3. Read the evaluation criterions and ensure you understand them well.\n",
    "4. Assess for each evaluation criteria the question given blogpost\n",
    "5. Assign a score from 1 to 5 (5 being best) for each evaluation criteria.\n",
    "\n",
    "Evaluation Criterias:\n",
    "Fluency (1-5): the quality of the question in terms of grammar, spelling, punctuation, word choice, and sentence structure.\n",
    "Relevance (1-5) - selection of important content from the source. The question should include only important issues or problems from the source document. \n",
    "Coherence (1-5) - the collective quality of the question. The question should be well-structured and well-organized\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "Question:\n",
    "{row['cleaned_questions']}\n",
    "\n",
    "Blogpost (in JSON format):\n",
    "{row['text']}\n",
    "\n",
    "Evaluation Form (scores ONLY):\n",
    "- Fluency (1-5):\n",
    "- Relevance (1-5):\n",
    "- Coherence (1-5):\n",
    "                \n",
    "Your answer must be in the format of a Python dictionary (and nothing else), e.g: \n",
    "{example_dict}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "        \n",
    "    question_metrics = ast.literal_eval(get_gpt(prompt))\n",
    "\n",
    "    return question_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: The server is overloaded or not ready yet.\n",
      "An error occurred: The server is overloaded or not ready yet.\n",
      "An error occurred: Rate limit reached for gpt-3.5-turbo in organization org-QqrrdoR3kZPjpGbc33YokvRb on tokens per min (TPM): Limit 60000, Used 58728, Requested 2465. Please try again in 1.193s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "An error occurred: Rate limit reached for gpt-3.5-turbo in organization org-QqrrdoR3kZPjpGbc33YokvRb on tokens per min (TPM): Limit 60000, Used 57609, Requested 2465. Please try again in 74ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "An error occurred: Rate limit reached for gpt-3.5-turbo in organization org-QqrrdoR3kZPjpGbc33YokvRb on tokens per min (TPM): Limit 60000, Used 56861, Requested 4096. Please try again in 956ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "An error occurred: Rate limit reached for gpt-3.5-turbo in organization org-QqrrdoR3kZPjpGbc33YokvRb on tokens per min (TPM): Limit 60000, Used 56132, Requested 4096. Please try again in 228ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "An error occurred: Rate limit reached for gpt-3.5-turbo in organization org-QqrrdoR3kZPjpGbc33YokvRb on tokens per min (TPM): Limit 60000, Used 58967, Requested 4096. Please try again in 3.063s. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "An error occurred: Rate limit reached for gpt-3.5-turbo in organization org-QqrrdoR3kZPjpGbc33YokvRb on tokens per min (TPM): Limit 60000, Used 56357, Requested 4096. Please try again in 453ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n",
      "An error occurred: Rate limit reached for gpt-3.5-turbo in organization org-QqrrdoR3kZPjpGbc33YokvRb on tokens per min (TPM): Limit 60000, Used 56514, Requested 3903. Please try again in 417ms. Visit https://platform.openai.com/account/rate-limits to learn more.\n"
     ]
    }
   ],
   "source": [
    "# Add evaluations to df \n",
    "evaluations = df.apply(evaluate_question, axis=1)\n",
    "df['evaluations_llama7b_q'] = evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0007\n",
      "0.0013\n",
      "0.002\n",
      "0.0026\n",
      "0.0033\n",
      "0.004\n",
      "0.0046\n",
      "0.0053\n",
      "0.006\n",
      "0.0066\n",
      "0.0073\n",
      "0.0079\n",
      "0.0086\n",
      "0.0093\n",
      "0.0099\n",
      "0.0106\n",
      "0.0113\n",
      "0.0119\n",
      "0.0126\n",
      "0.0132\n",
      "0.0139\n",
      "0.0146\n",
      "0.0152\n",
      "0.0159\n",
      "0.0165\n",
      "0.0172\n",
      "0.0179\n",
      "0.0185\n",
      "0.0192\n",
      "0.0199\n",
      "0.0205\n",
      "0.0212\n",
      "0.0218\n",
      "0.0225\n",
      "0.0232\n",
      "0.0238\n",
      "0.0245\n",
      "0.0251\n",
      "0.0258\n",
      "0.0265\n",
      "0.0271\n",
      "0.0278\n",
      "0.0285\n",
      "0.0291\n",
      "0.0298\n",
      "0.0304\n",
      "0.0311\n",
      "0.0318\n",
      "0.0324\n",
      "0.0331\n",
      "0.0338\n",
      "0.0344\n",
      "0.0351\n",
      "0.0357\n",
      "0.0364\n",
      "0.0371\n",
      "0.0377\n",
      "0.0384\n",
      "0.039\n",
      "0.0397\n",
      "0.0404\n",
      "0.041\n",
      "0.0417\n",
      "0.0424\n",
      "0.043\n",
      "0.0437\n",
      "0.0443\n",
      "0.045\n",
      "0.0457\n",
      "0.0463\n",
      "0.047\n",
      "0.0477\n",
      "0.0483\n",
      "0.049\n",
      "0.0496\n",
      "0.0503\n",
      "0.051\n",
      "0.0516\n",
      "0.0523\n",
      "0.0529\n",
      "0.0536\n",
      "0.0543\n",
      "0.0549\n",
      "0.0556\n",
      "0.0563\n",
      "0.0569\n",
      "0.0576\n",
      "0.0582\n",
      "0.0589\n",
      "0.0596\n",
      "0.0602\n",
      "0.0609\n",
      "0.0615\n",
      "0.0622\n",
      "0.0629\n",
      "0.0635\n",
      "0.0642\n",
      "0.0649\n",
      "0.0655\n",
      "0.0662\n",
      "0.0668\n",
      "0.0675\n",
      "0.0682\n",
      "0.0688\n",
      "0.0695\n",
      "0.0702\n",
      "0.0708\n",
      "0.0715\n",
      "0.0721\n",
      "0.0728\n",
      "0.0735\n",
      "0.0741\n",
      "0.0748\n",
      "0.0754\n",
      "0.0761\n",
      "0.0768\n",
      "0.0774\n",
      "0.0781\n",
      "0.0788\n",
      "0.0794\n",
      "0.0801\n",
      "0.0807\n",
      "0.0814\n",
      "0.0821\n",
      "0.0827\n",
      "0.0834\n",
      "0.0841\n",
      "0.0847\n",
      "0.0854\n",
      "0.086\n",
      "0.0867\n",
      "0.0874\n",
      "0.088\n",
      "0.0887\n",
      "0.0893\n",
      "0.09\n",
      "0.0907\n",
      "0.0913\n",
      "0.092\n",
      "0.0927\n",
      "0.0933\n",
      "0.094\n",
      "0.0946\n",
      "0.0953\n",
      "0.096\n",
      "0.0966\n",
      "0.0973\n",
      "0.0979\n",
      "0.0986\n",
      "0.0993\n",
      "0.0999\n",
      "0.1006\n",
      "0.1013\n",
      "0.1019\n",
      "0.1026\n",
      "0.1032\n",
      "0.1039\n",
      "0.1046\n",
      "0.1052\n",
      "0.1059\n",
      "0.1066\n",
      "0.1072\n",
      "0.1079\n",
      "0.1085\n",
      "0.1092\n",
      "0.1099\n",
      "0.1105\n",
      "0.1112\n",
      "0.1118\n",
      "0.1125\n",
      "0.1132\n",
      "0.1138\n",
      "0.1145\n",
      "0.1152\n",
      "0.1158\n",
      "0.1165\n",
      "0.1171\n",
      "0.1178\n",
      "0.1185\n",
      "0.1191\n",
      "0.1198\n",
      "0.1205\n",
      "0.1211\n",
      "0.1218\n",
      "0.1224\n",
      "0.1231\n",
      "0.1238\n",
      "0.1244\n",
      "0.1251\n",
      "0.1257\n",
      "0.1264\n",
      "0.1271\n",
      "0.1277\n",
      "0.1284\n",
      "0.1291\n",
      "0.1297\n",
      "0.1304\n",
      "0.131\n",
      "0.1317\n",
      "0.1324\n",
      "0.133\n",
      "0.1337\n",
      "0.1343\n",
      "0.135\n",
      "0.1357\n",
      "0.1363\n",
      "0.137\n",
      "0.1377\n",
      "0.1383\n",
      "0.139\n",
      "0.1396\n",
      "0.1403\n",
      "0.141\n",
      "0.1416\n",
      "0.1423\n",
      "0.143\n",
      "0.1436\n",
      "0.1443\n",
      "0.1449\n",
      "0.1456\n",
      "0.1463\n",
      "0.1469\n",
      "0.1476\n",
      "0.1482\n",
      "0.1489\n",
      "0.1496\n",
      "0.1502\n",
      "0.1509\n",
      "0.1516\n",
      "0.1522\n",
      "0.1529\n",
      "0.1535\n",
      "0.1542\n",
      "0.1549\n",
      "0.1555\n",
      "0.1562\n",
      "0.1568\n",
      "0.1575\n",
      "0.1582\n",
      "0.1588\n",
      "0.1595\n",
      "0.1602\n",
      "0.1608\n",
      "0.1615\n",
      "0.1621\n",
      "0.1628\n",
      "0.1635\n",
      "0.1641\n",
      "0.1648\n",
      "0.1655\n",
      "0.1661\n",
      "0.1668\n",
      "0.1674\n",
      "0.1681\n",
      "0.1688\n",
      "0.1694\n",
      "0.1701\n",
      "0.1707\n",
      "0.1714\n",
      "0.1721\n",
      "0.1727\n",
      "0.1734\n",
      "0.1741\n",
      "0.1747\n",
      "0.1754\n",
      "0.176\n",
      "0.1767\n",
      "0.1774\n",
      "0.178\n",
      "0.1787\n",
      "0.1794\n",
      "0.18\n",
      "0.1807\n",
      "0.1813\n",
      "0.182\n",
      "0.1827\n",
      "0.1833\n",
      "0.184\n",
      "0.1846\n",
      "0.1853\n",
      "0.186\n",
      "0.1866\n",
      "0.1873\n",
      "0.188\n",
      "0.1886\n",
      "0.1893\n",
      "0.1899\n",
      "0.1906\n",
      "0.1913\n",
      "0.1919\n",
      "0.1926\n",
      "0.1932\n",
      "0.1939\n",
      "0.1946\n",
      "0.1952\n",
      "0.1959\n",
      "0.1966\n",
      "0.1972\n",
      "0.1979\n",
      "0.1985\n",
      "0.1992\n",
      "0.1999\n",
      "0.2005\n",
      "0.2012\n",
      "0.2019\n",
      "0.2025\n",
      "0.2032\n",
      "0.2038\n",
      "0.2045\n",
      "0.2052\n",
      "0.2058\n",
      "0.2065\n",
      "0.2071\n",
      "0.2078\n",
      "0.2085\n",
      "0.2091\n",
      "0.2098\n",
      "0.2105\n",
      "0.2111\n",
      "0.2118\n",
      "0.2124\n",
      "0.2131\n",
      "0.2138\n",
      "0.2144\n",
      "0.2151\n",
      "0.2158\n",
      "0.2164\n",
      "0.2171\n",
      "0.2177\n",
      "0.2184\n",
      "0.2191\n",
      "0.2197\n",
      "0.2204\n",
      "0.221\n",
      "0.2217\n",
      "0.2224\n",
      "0.223\n",
      "0.2237\n",
      "0.2244\n",
      "0.225\n",
      "0.2257\n",
      "0.2263\n",
      "0.227\n",
      "0.2277\n",
      "0.2283\n",
      "0.229\n",
      "0.2296\n",
      "0.2303\n",
      "0.231\n",
      "0.2316\n",
      "0.2323\n",
      "0.233\n",
      "0.2336\n",
      "0.2343\n",
      "0.2349\n",
      "0.2356\n",
      "0.2363\n",
      "0.2369\n",
      "0.2376\n",
      "0.2383\n",
      "0.2389\n",
      "0.2396\n",
      "0.2402\n",
      "0.2409\n",
      "0.2416\n",
      "0.2422\n",
      "0.2429\n",
      "0.2435\n",
      "0.2442\n",
      "0.2449\n",
      "0.2455\n",
      "0.2462\n",
      "0.2469\n",
      "0.2475\n",
      "0.2482\n",
      "0.2488\n",
      "0.2495\n",
      "0.2502\n",
      "0.2508\n",
      "0.2515\n",
      "0.2522\n",
      "0.2528\n",
      "0.2535\n",
      "0.2541\n",
      "0.2548\n",
      "0.2555\n",
      "0.2561\n",
      "0.2568\n",
      "0.2574\n",
      "0.2581\n",
      "0.2588\n",
      "0.2594\n",
      "0.2601\n",
      "0.2608\n",
      "0.2614\n",
      "0.2621\n",
      "0.2627\n",
      "0.2634\n",
      "0.2641\n",
      "0.2647\n",
      "0.2654\n",
      "0.266\n",
      "0.2667\n",
      "0.2674\n",
      "0.268\n",
      "0.2687\n",
      "0.2694\n",
      "0.27\n",
      "0.2707\n",
      "0.2713\n",
      "0.272\n",
      "0.2727\n",
      "0.2733\n",
      "0.274\n",
      "0.2747\n",
      "0.2753\n",
      "0.276\n",
      "0.2766\n",
      "0.2773\n",
      "0.278\n",
      "0.2786\n",
      "0.2793\n",
      "0.2799\n",
      "0.2806\n",
      "0.2813\n",
      "0.2819\n",
      "0.2826\n",
      "0.2833\n",
      "0.2839\n",
      "0.2846\n",
      "0.2852\n",
      "0.2859\n",
      "0.2866\n",
      "0.2872\n",
      "0.2879\n",
      "0.2886\n",
      "0.2892\n",
      "0.2899\n",
      "0.2905\n",
      "0.2912\n",
      "0.2919\n",
      "0.2925\n",
      "0.2932\n",
      "0.2938\n",
      "0.2945\n",
      "0.2952\n",
      "0.2958\n",
      "0.2965\n",
      "0.2972\n",
      "0.2978\n",
      "0.2985\n",
      "0.2991\n",
      "0.2998\n",
      "0.3005\n",
      "0.3011\n",
      "0.3018\n",
      "0.3024\n",
      "0.3031\n",
      "0.3038\n",
      "0.3044\n",
      "0.3051\n",
      "0.3058\n",
      "0.3064\n",
      "0.3071\n",
      "0.3077\n",
      "0.3084\n",
      "0.3091\n",
      "0.3097\n",
      "0.3104\n",
      "0.3111\n",
      "0.3117\n",
      "0.3124\n",
      "0.313\n",
      "0.3137\n",
      "0.3144\n",
      "0.315\n",
      "0.3157\n",
      "0.3163\n",
      "0.317\n",
      "0.3177\n",
      "0.3183\n",
      "0.319\n",
      "0.3197\n",
      "0.3203\n",
      "0.321\n",
      "0.3216\n",
      "0.3223\n",
      "0.323\n",
      "0.3236\n",
      "0.3243\n",
      "0.325\n",
      "0.3256\n",
      "0.3263\n",
      "0.3269\n",
      "0.3276\n",
      "0.3283\n",
      "0.3289\n",
      "0.3296\n",
      "0.3302\n",
      "0.3309\n",
      "0.3316\n",
      "0.3322\n",
      "0.3329\n",
      "0.3336\n",
      "0.3342\n",
      "0.3349\n",
      "0.3355\n",
      "0.3362\n",
      "0.3369\n",
      "0.3375\n",
      "0.3382\n",
      "0.3388\n",
      "0.3395\n",
      "0.3402\n",
      "0.3408\n",
      "0.3415\n",
      "0.3422\n",
      "0.3428\n",
      "0.3435\n",
      "0.3441\n",
      "0.3448\n",
      "0.3455\n",
      "0.3461\n",
      "0.3468\n",
      "0.3475\n",
      "0.3481\n",
      "0.3488\n",
      "0.3494\n",
      "0.3501\n",
      "0.3508\n",
      "0.3514\n",
      "0.3521\n",
      "0.3527\n",
      "0.3534\n",
      "0.3541\n",
      "0.3547\n",
      "0.3554\n",
      "0.3561\n",
      "0.3567\n",
      "0.3574\n",
      "0.358\n",
      "0.3587\n",
      "0.3594\n",
      "0.36\n",
      "0.3607\n",
      "0.3614\n",
      "0.362\n",
      "0.3627\n",
      "0.3633\n",
      "0.364\n",
      "0.3647\n",
      "0.3653\n",
      "0.366\n",
      "0.3666\n",
      "0.3673\n",
      "0.368\n",
      "0.3686\n",
      "0.3693\n",
      "0.37\n",
      "0.3706\n",
      "0.3713\n",
      "0.3719\n",
      "0.3726\n",
      "0.3733\n",
      "0.3739\n",
      "0.3746\n",
      "0.3752\n",
      "0.3759\n",
      "0.3766\n",
      "0.3772\n",
      "0.3779\n",
      "0.3786\n",
      "0.3792\n",
      "0.3799\n",
      "0.3805\n",
      "0.3812\n",
      "0.3819\n",
      "0.3825\n",
      "0.3832\n",
      "0.3839\n",
      "0.3845\n",
      "0.3852\n",
      "0.3858\n",
      "0.3865\n",
      "0.3872\n",
      "0.3878\n",
      "0.3885\n",
      "0.3891\n",
      "0.3898\n",
      "0.3905\n",
      "0.3911\n",
      "0.3918\n",
      "0.3925\n",
      "0.3931\n",
      "0.3938\n",
      "An error occurred: Prediction interrupted; please retry (code: PA)\n",
      "Retrying in 20 seconds...\n",
      "0.3944\n",
      "0.3951\n",
      "0.3958\n",
      "0.3964\n",
      "0.3971\n",
      "0.3977\n",
      "0.3984\n",
      "0.3991\n",
      "0.3997\n",
      "0.4004\n",
      "0.4011\n",
      "0.4017\n",
      "0.4024\n",
      "0.403\n",
      "0.4037\n",
      "0.4044\n",
      "0.405\n",
      "0.4057\n",
      "0.4064\n",
      "0.407\n",
      "0.4077\n",
      "0.4083\n",
      "0.409\n",
      "0.4097\n",
      "0.4103\n",
      "0.411\n",
      "0.4116\n",
      "0.4123\n",
      "0.413\n",
      "0.4136\n",
      "0.4143\n",
      "0.415\n",
      "0.4156\n",
      "0.4163\n",
      "0.4169\n",
      "0.4176\n",
      "0.4183\n",
      "0.4189\n",
      "0.4196\n",
      "0.4203\n",
      "0.4209\n",
      "0.4216\n",
      "0.4222\n",
      "0.4229\n",
      "0.4236\n",
      "0.4242\n",
      "0.4249\n",
      "0.4255\n",
      "0.4262\n",
      "0.4269\n",
      "0.4275\n",
      "0.4282\n",
      "0.4289\n",
      "0.4295\n",
      "0.4302\n",
      "0.4308\n",
      "0.4315\n",
      "0.4322\n",
      "0.4328\n",
      "0.4335\n",
      "0.4341\n",
      "0.4348\n",
      "0.4355\n",
      "0.4361\n",
      "0.4368\n",
      "0.4375\n",
      "0.4381\n",
      "0.4388\n",
      "0.4394\n",
      "0.4401\n",
      "0.4408\n",
      "0.4414\n",
      "0.4421\n",
      "0.4428\n",
      "0.4434\n",
      "0.4441\n",
      "0.4447\n",
      "0.4454\n",
      "0.4461\n",
      "0.4467\n",
      "0.4474\n",
      "0.448\n",
      "0.4487\n",
      "0.4494\n",
      "0.45\n",
      "0.4507\n",
      "0.4514\n",
      "0.452\n",
      "0.4527\n",
      "0.4533\n",
      "0.454\n",
      "0.4547\n",
      "0.4553\n",
      "0.456\n",
      "0.4567\n",
      "0.4573\n",
      "0.458\n",
      "0.4586\n",
      "0.4593\n",
      "0.46\n",
      "0.4606\n",
      "0.4613\n",
      "0.4619\n",
      "0.4626\n",
      "0.4633\n",
      "0.4639\n",
      "0.4646\n",
      "0.4653\n",
      "0.4659\n",
      "0.4666\n",
      "0.4672\n",
      "0.4679\n",
      "0.4686\n",
      "0.4692\n",
      "0.4699\n",
      "0.4705\n",
      "0.4712\n",
      "0.4719\n",
      "0.4725\n",
      "0.4732\n",
      "0.4739\n",
      "0.4745\n",
      "0.4752\n",
      "0.4758\n",
      "0.4765\n",
      "0.4772\n",
      "0.4778\n",
      "0.4785\n",
      "0.4792\n",
      "0.4798\n",
      "0.4805\n",
      "0.4811\n",
      "0.4818\n",
      "0.4825\n",
      "0.4831\n",
      "0.4838\n",
      "0.4844\n",
      "0.4851\n",
      "0.4858\n",
      "0.4864\n",
      "0.4871\n",
      "0.4878\n",
      "0.4884\n",
      "0.4891\n",
      "0.4897\n",
      "0.4904\n",
      "0.4911\n",
      "0.4917\n",
      "0.4924\n",
      "0.4931\n",
      "0.4937\n",
      "0.4944\n",
      "0.495\n",
      "0.4957\n",
      "0.4964\n",
      "0.497\n",
      "0.4977\n",
      "0.4983\n",
      "0.499\n",
      "0.4997\n",
      "0.5003\n",
      "0.501\n",
      "0.5017\n",
      "0.5023\n",
      "0.503\n",
      "0.5036\n",
      "0.5043\n",
      "0.505\n",
      "0.5056\n",
      "0.5063\n",
      "0.5069\n",
      "0.5076\n",
      "0.5083\n",
      "0.5089\n",
      "0.5096\n",
      "0.5103\n",
      "0.5109\n",
      "0.5116\n",
      "0.5122\n",
      "0.5129\n",
      "0.5136\n",
      "0.5142\n",
      "0.5149\n",
      "0.5156\n",
      "0.5162\n",
      "0.5169\n",
      "0.5175\n",
      "0.5182\n",
      "0.5189\n",
      "0.5195\n",
      "0.5202\n",
      "0.5208\n",
      "0.5215\n",
      "0.5222\n",
      "0.5228\n",
      "0.5235\n",
      "0.5242\n",
      "0.5248\n",
      "0.5255\n",
      "0.5261\n",
      "0.5268\n",
      "0.5275\n",
      "0.5281\n",
      "0.5288\n",
      "0.5295\n",
      "0.5301\n",
      "0.5308\n",
      "0.5314\n",
      "0.5321\n",
      "0.5328\n",
      "0.5334\n",
      "0.5341\n",
      "0.5347\n",
      "0.5354\n",
      "0.5361\n",
      "0.5367\n",
      "0.5374\n",
      "0.5381\n",
      "0.5387\n",
      "0.5394\n",
      "0.54\n",
      "0.5407\n",
      "0.5414\n",
      "0.542\n",
      "0.5427\n",
      "0.5433\n",
      "0.544\n",
      "0.5447\n",
      "0.5453\n",
      "0.546\n",
      "0.5467\n",
      "0.5473\n",
      "0.548\n",
      "0.5486\n",
      "0.5493\n",
      "0.55\n",
      "0.5506\n",
      "0.5513\n",
      "0.552\n",
      "0.5526\n",
      "0.5533\n",
      "0.5539\n",
      "0.5546\n",
      "0.5553\n",
      "0.5559\n",
      "0.5566\n",
      "0.5572\n",
      "0.5579\n",
      "0.5586\n",
      "0.5592\n",
      "0.5599\n",
      "0.5606\n",
      "0.5612\n",
      "0.5619\n",
      "0.5625\n",
      "0.5632\n",
      "0.5639\n",
      "0.5645\n",
      "0.5652\n",
      "0.5659\n",
      "0.5665\n",
      "0.5672\n",
      "0.5678\n",
      "0.5685\n",
      "0.5692\n",
      "0.5698\n",
      "0.5705\n",
      "0.5711\n",
      "0.5718\n",
      "0.5725\n",
      "0.5731\n",
      "0.5738\n",
      "0.5745\n",
      "0.5751\n",
      "0.5758\n",
      "0.5764\n",
      "0.5771\n",
      "0.5778\n",
      "0.5784\n",
      "0.5791\n",
      "0.5797\n",
      "0.5804\n",
      "0.5811\n",
      "0.5817\n",
      "0.5824\n",
      "0.5831\n",
      "0.5837\n",
      "0.5844\n",
      "0.585\n",
      "0.5857\n",
      "0.5864\n",
      "0.587\n",
      "0.5877\n",
      "0.5884\n",
      "0.589\n",
      "0.5897\n",
      "0.5903\n",
      "0.591\n",
      "0.5917\n",
      "0.5923\n",
      "0.593\n",
      "0.5936\n",
      "0.5943\n",
      "0.595\n",
      "0.5956\n",
      "0.5963\n",
      "0.597\n",
      "0.5976\n",
      "0.5983\n",
      "0.5989\n",
      "0.5996\n",
      "0.6003\n",
      "0.6009\n",
      "0.6016\n",
      "0.6023\n",
      "0.6029\n",
      "0.6036\n",
      "0.6042\n",
      "0.6049\n",
      "0.6056\n",
      "0.6062\n",
      "0.6069\n",
      "0.6075\n",
      "0.6082\n",
      "0.6089\n",
      "0.6095\n",
      "0.6102\n",
      "0.6109\n",
      "0.6115\n",
      "0.6122\n",
      "0.6128\n",
      "0.6135\n",
      "0.6142\n",
      "0.6148\n",
      "0.6155\n",
      "0.6161\n",
      "0.6168\n",
      "0.6175\n",
      "0.6181\n",
      "0.6188\n",
      "0.6195\n",
      "0.6201\n",
      "0.6208\n",
      "0.6214\n",
      "0.6221\n",
      "0.6228\n",
      "0.6234\n",
      "0.6241\n",
      "0.6248\n",
      "0.6254\n",
      "0.6261\n",
      "0.6267\n",
      "0.6274\n",
      "0.6281\n",
      "0.6287\n",
      "0.6294\n",
      "0.63\n",
      "0.6307\n",
      "0.6314\n",
      "0.632\n",
      "0.6327\n",
      "0.6334\n",
      "0.634\n",
      "0.6347\n",
      "0.6353\n",
      "0.636\n",
      "0.6367\n",
      "0.6373\n",
      "0.638\n",
      "0.6386\n",
      "0.6393\n",
      "0.64\n",
      "0.6406\n",
      "0.6413\n",
      "0.642\n",
      "0.6426\n",
      "0.6433\n",
      "0.6439\n",
      "0.6446\n",
      "0.6453\n",
      "0.6459\n",
      "0.6466\n",
      "0.6473\n",
      "0.6479\n",
      "0.6486\n",
      "0.6492\n",
      "0.6499\n",
      "0.6506\n",
      "0.6512\n",
      "0.6519\n",
      "0.6525\n",
      "0.6532\n",
      "0.6539\n",
      "0.6545\n",
      "0.6552\n",
      "0.6559\n",
      "0.6565\n",
      "0.6572\n",
      "0.6578\n",
      "0.6585\n",
      "0.6592\n",
      "0.6598\n",
      "0.6605\n",
      "0.6612\n",
      "0.6618\n",
      "0.6625\n",
      "0.6631\n",
      "0.6638\n",
      "0.6645\n",
      "0.6651\n",
      "0.6658\n",
      "0.6664\n",
      "0.6671\n",
      "0.6678\n",
      "0.6684\n",
      "0.6691\n",
      "0.6698\n",
      "0.6704\n",
      "0.6711\n",
      "0.6717\n",
      "0.6724\n",
      "0.6731\n",
      "0.6737\n",
      "0.6744\n",
      "0.675\n",
      "0.6757\n",
      "0.6764\n",
      "0.677\n",
      "0.6777\n",
      "0.6784\n",
      "0.679\n",
      "0.6797\n",
      "0.6803\n",
      "0.681\n",
      "0.6817\n",
      "0.6823\n",
      "0.683\n",
      "0.6837\n",
      "0.6843\n",
      "0.685\n",
      "0.6856\n",
      "0.6863\n",
      "0.687\n",
      "0.6876\n",
      "0.6883\n",
      "0.6889\n",
      "0.6896\n",
      "0.6903\n",
      "0.6909\n",
      "0.6916\n",
      "0.6923\n",
      "0.6929\n",
      "0.6936\n",
      "0.6942\n",
      "0.6949\n",
      "0.6956\n",
      "0.6962\n",
      "0.6969\n",
      "0.6976\n",
      "0.6982\n",
      "0.6989\n",
      "0.6995\n",
      "0.7002\n",
      "0.7009\n",
      "0.7015\n",
      "0.7022\n",
      "0.7028\n",
      "0.7035\n",
      "0.7042\n",
      "0.7048\n",
      "0.7055\n",
      "0.7062\n",
      "0.7068\n",
      "0.7075\n",
      "0.7081\n",
      "0.7088\n",
      "0.7095\n",
      "0.7101\n",
      "0.7108\n",
      "0.7114\n",
      "0.7121\n",
      "0.7128\n",
      "0.7134\n",
      "0.7141\n",
      "0.7148\n",
      "0.7154\n",
      "0.7161\n",
      "0.7167\n",
      "0.7174\n",
      "0.7181\n",
      "0.7187\n",
      "0.7194\n",
      "0.7201\n",
      "0.7207\n",
      "0.7214\n",
      "0.722\n",
      "0.7227\n",
      "0.7234\n",
      "0.724\n",
      "0.7247\n",
      "0.7253\n",
      "0.726\n",
      "0.7267\n",
      "0.7273\n",
      "0.728\n",
      "0.7287\n",
      "0.7293\n",
      "0.73\n",
      "0.7306\n",
      "0.7313\n",
      "0.732\n",
      "0.7326\n",
      "0.7333\n",
      "0.734\n",
      "0.7346\n",
      "0.7353\n",
      "0.7359\n",
      "0.7366\n",
      "0.7373\n",
      "0.7379\n",
      "0.7386\n",
      "0.7392\n",
      "0.7399\n",
      "0.7406\n",
      "0.7412\n",
      "0.7419\n",
      "0.7426\n",
      "0.7432\n",
      "0.7439\n",
      "0.7445\n",
      "0.7452\n",
      "0.7459\n",
      "0.7465\n",
      "0.7472\n",
      "0.7478\n",
      "0.7485\n",
      "0.7492\n",
      "0.7498\n",
      "0.7505\n",
      "0.7512\n",
      "0.7518\n",
      "0.7525\n",
      "0.7531\n",
      "0.7538\n",
      "0.7545\n",
      "0.7551\n",
      "0.7558\n",
      "0.7565\n",
      "0.7571\n",
      "0.7578\n",
      "0.7584\n",
      "0.7591\n",
      "0.7598\n",
      "0.7604\n",
      "0.7611\n",
      "0.7617\n",
      "0.7624\n",
      "0.7631\n",
      "0.7637\n",
      "0.7644\n",
      "0.7651\n",
      "0.7657\n",
      "0.7664\n",
      "0.767\n",
      "0.7677\n",
      "0.7684\n",
      "0.769\n",
      "0.7697\n",
      "0.7704\n",
      "0.771\n",
      "0.7717\n",
      "0.7723\n",
      "0.773\n",
      "0.7737\n",
      "0.7743\n",
      "0.775\n",
      "0.7756\n",
      "0.7763\n",
      "0.777\n",
      "0.7776\n",
      "0.7783\n",
      "0.779\n",
      "0.7796\n",
      "0.7803\n",
      "0.7809\n",
      "0.7816\n",
      "0.7823\n",
      "0.7829\n",
      "0.7836\n",
      "0.7842\n",
      "0.7849\n",
      "0.7856\n",
      "0.7862\n",
      "0.7869\n",
      "0.7876\n",
      "0.7882\n",
      "0.7889\n",
      "0.7895\n",
      "0.7902\n",
      "0.7909\n",
      "0.7915\n",
      "0.7922\n",
      "0.7929\n",
      "0.7935\n",
      "0.7942\n",
      "0.7948\n",
      "0.7955\n",
      "0.7962\n",
      "0.7968\n",
      "0.7975\n",
      "0.7981\n",
      "0.7988\n",
      "0.7995\n",
      "0.8001\n",
      "0.8008\n",
      "0.8015\n",
      "0.8021\n",
      "0.8028\n",
      "0.8034\n",
      "0.8041\n",
      "0.8048\n",
      "0.8054\n",
      "0.8061\n",
      "0.8068\n",
      "0.8074\n",
      "0.8081\n",
      "0.8087\n",
      "0.8094\n",
      "0.8101\n",
      "0.8107\n",
      "0.8114\n",
      "0.812\n",
      "0.8127\n",
      "0.8134\n",
      "0.814\n",
      "0.8147\n",
      "0.8154\n",
      "0.816\n",
      "0.8167\n",
      "0.8173\n",
      "0.818\n",
      "0.8187\n",
      "0.8193\n",
      "0.82\n",
      "0.8206\n",
      "0.8213\n",
      "0.822\n",
      "0.8226\n",
      "0.8233\n",
      "0.824\n",
      "0.8246\n",
      "0.8253\n",
      "0.8259\n",
      "0.8266\n",
      "0.8273\n",
      "0.8279\n",
      "0.8286\n",
      "0.8293\n",
      "0.8299\n",
      "0.8306\n",
      "0.8312\n",
      "0.8319\n",
      "0.8326\n",
      "0.8332\n",
      "0.8339\n",
      "0.8345\n",
      "0.8352\n",
      "0.8359\n",
      "0.8365\n",
      "0.8372\n",
      "0.8379\n",
      "0.8385\n",
      "0.8392\n",
      "0.8398\n",
      "0.8405\n",
      "0.8412\n",
      "0.8418\n",
      "0.8425\n",
      "0.8432\n",
      "0.8438\n",
      "0.8445\n",
      "0.8451\n",
      "0.8458\n",
      "0.8465\n",
      "0.8471\n",
      "0.8478\n",
      "0.8484\n",
      "0.8491\n",
      "0.8498\n",
      "0.8504\n",
      "0.8511\n",
      "0.8518\n",
      "0.8524\n",
      "0.8531\n",
      "0.8537\n",
      "0.8544\n",
      "0.8551\n",
      "0.8557\n",
      "0.8564\n",
      "0.857\n",
      "0.8577\n",
      "0.8584\n",
      "0.859\n",
      "0.8597\n",
      "0.8604\n",
      "0.861\n",
      "0.8617\n",
      "0.8623\n",
      "0.863\n",
      "0.8637\n",
      "0.8643\n",
      "0.865\n",
      "0.8657\n",
      "0.8663\n",
      "0.867\n",
      "0.8676\n",
      "0.8683\n",
      "0.869\n",
      "0.8696\n",
      "0.8703\n",
      "0.8709\n",
      "0.8716\n",
      "0.8723\n",
      "0.8729\n",
      "0.8736\n",
      "0.8743\n",
      "0.8749\n",
      "0.8756\n",
      "0.8762\n",
      "0.8769\n",
      "0.8776\n",
      "0.8782\n",
      "0.8789\n",
      "0.8795\n",
      "0.8802\n",
      "0.8809\n",
      "0.8815\n",
      "0.8822\n",
      "0.8829\n",
      "0.8835\n",
      "0.8842\n",
      "0.8848\n",
      "0.8855\n",
      "0.8862\n",
      "0.8868\n",
      "0.8875\n",
      "0.8882\n",
      "0.8888\n",
      "0.8895\n",
      "0.8901\n",
      "0.8908\n",
      "0.8915\n",
      "0.8921\n",
      "0.8928\n",
      "0.8934\n",
      "0.8941\n",
      "0.8948\n",
      "0.8954\n",
      "0.8961\n",
      "0.8968\n",
      "0.8974\n",
      "0.8981\n",
      "0.8987\n",
      "0.8994\n",
      "0.9001\n",
      "0.9007\n",
      "0.9014\n",
      "0.9021\n",
      "0.9027\n",
      "0.9034\n",
      "0.904\n",
      "0.9047\n",
      "0.9054\n",
      "0.906\n",
      "0.9067\n",
      "0.9073\n",
      "0.908\n",
      "0.9087\n",
      "0.9093\n",
      "0.91\n",
      "0.9107\n",
      "0.9113\n",
      "0.912\n",
      "0.9126\n",
      "0.9133\n",
      "0.914\n",
      "0.9146\n",
      "0.9153\n",
      "0.9159\n",
      "0.9166\n",
      "0.9173\n",
      "0.9179\n",
      "0.9186\n",
      "0.9193\n",
      "0.9199\n",
      "0.9206\n",
      "0.9212\n",
      "0.9219\n",
      "0.9226\n",
      "0.9232\n",
      "0.9239\n",
      "0.9246\n",
      "0.9252\n",
      "0.9259\n",
      "0.9265\n",
      "0.9272\n",
      "0.9279\n",
      "0.9285\n",
      "0.9292\n",
      "0.9298\n",
      "0.9305\n",
      "0.9312\n",
      "0.9318\n",
      "0.9325\n",
      "0.9332\n",
      "0.9338\n",
      "0.9345\n",
      "0.9351\n",
      "0.9358\n",
      "0.9365\n",
      "0.9371\n",
      "0.9378\n",
      "0.9385\n",
      "0.9391\n",
      "0.9398\n",
      "0.9404\n",
      "0.9411\n",
      "0.9418\n",
      "0.9424\n",
      "0.9431\n",
      "0.9437\n",
      "0.9444\n",
      "0.9451\n",
      "0.9457\n",
      "0.9464\n",
      "0.9471\n",
      "0.9477\n",
      "0.9484\n",
      "0.949\n",
      "0.9497\n",
      "0.9504\n",
      "0.951\n",
      "0.9517\n",
      "0.9523\n",
      "0.953\n",
      "0.9537\n",
      "0.9543\n",
      "0.955\n",
      "0.9557\n",
      "0.9563\n",
      "0.957\n",
      "0.9576\n",
      "0.9583\n",
      "0.959\n",
      "0.9596\n",
      "0.9603\n",
      "0.961\n",
      "0.9616\n",
      "0.9623\n",
      "0.9629\n",
      "0.9636\n",
      "0.9643\n",
      "0.9649\n",
      "0.9656\n",
      "0.9662\n",
      "0.9669\n",
      "0.9676\n",
      "0.9682\n",
      "0.9689\n",
      "0.9696\n",
      "0.9702\n",
      "0.9709\n",
      "0.9715\n",
      "0.9722\n",
      "0.9729\n",
      "0.9735\n",
      "0.9742\n",
      "0.9749\n",
      "0.9755\n",
      "0.9762\n",
      "0.9768\n",
      "0.9775\n",
      "0.9782\n",
      "0.9788\n",
      "0.9795\n",
      "0.9801\n",
      "0.9808\n",
      "0.9815\n",
      "0.9821\n",
      "0.9828\n",
      "0.9835\n",
      "0.9841\n",
      "0.9848\n",
      "0.9854\n",
      "0.9861\n",
      "0.9868\n",
      "0.9874\n",
      "0.9881\n",
      "0.9887\n",
      "0.9894\n",
      "0.9901\n",
      "0.9907\n",
      "0.9914\n",
      "0.9921\n",
      "0.9927\n",
      "0.9934\n",
      "0.994\n",
      "0.9947\n",
      "0.9954\n",
      "0.996\n",
      "0.9967\n",
      "0.9974\n",
      "0.998\n",
      "0.9987\n",
      "0.9993\n"
     ]
    }
   ],
   "source": [
    "answers = []\n",
    "for index, row in df.iterrows():\n",
    "    prompt = f\"\"\" \n",
    "            This is an example of a blogpost from Bang and Olufsen's forum in JSON format:\n",
    "\n",
    "            {row['text']}\n",
    "\n",
    "            Your task is the answer this question:\n",
    "            {row['questions']}\n",
    "\n",
    "            Read the post and answer the question concisely.\n",
    "\n",
    "            There are some rules:\n",
    "            - Only reply with the answer to the question above\n",
    "            - If the thread does not consists of a solution, please state that the answer cannot be answered\n",
    "            - Do not mention usernames \n",
    "            \"\"\"\n",
    "    answers.append(get_llama(prompt))\n",
    "    print(round(index/len(df),4))\n",
    "\n",
    "df['answers'] = answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9332\n",
      "0.9338\n",
      "0.9345\n",
      "0.9351\n",
      "0.9358\n",
      "0.9365\n",
      "0.9371\n",
      "0.9378\n",
      "0.9385\n",
      "0.9391\n",
      "0.9398\n",
      "0.9404\n",
      "0.9411\n",
      "0.9418\n",
      "0.9424\n",
      "0.9431\n",
      "0.9437\n",
      "0.9444\n",
      "0.9451\n",
      "0.9457\n",
      "0.9464\n",
      "0.9471\n",
      "0.9477\n",
      "0.9484\n",
      "0.949\n",
      "0.9497\n",
      "0.9504\n",
      "0.951\n",
      "0.9517\n",
      "0.9523\n",
      "0.953\n",
      "0.9537\n",
      "0.9543\n",
      "0.955\n",
      "0.9557\n",
      "0.9563\n",
      "0.957\n",
      "0.9576\n",
      "0.9583\n",
      "0.959\n",
      "0.9596\n",
      "0.9603\n",
      "0.961\n",
      "0.9616\n",
      "0.9623\n",
      "0.9629\n",
      "0.9636\n",
      "0.9643\n",
      "0.9649\n",
      "0.9656\n",
      "0.9662\n",
      "0.9669\n",
      "0.9676\n",
      "0.9682\n",
      "0.9689\n",
      "0.9696\n",
      "0.9702\n",
      "0.9709\n",
      "0.9715\n",
      "0.9722\n",
      "0.9729\n",
      "0.9735\n",
      "0.9742\n",
      "0.9749\n",
      "0.9755\n",
      "0.9762\n",
      "0.9768\n",
      "0.9775\n",
      "0.9782\n",
      "0.9788\n",
      "0.9795\n",
      "0.9801\n",
      "0.9808\n",
      "0.9815\n",
      "0.9821\n",
      "0.9828\n",
      "0.9835\n",
      "0.9841\n",
      "0.9848\n",
      "0.9854\n",
      "0.9861\n",
      "0.9868\n",
      "0.9874\n",
      "0.9881\n",
      "0.9887\n",
      "0.9894\n",
      "0.9901\n",
      "0.9907\n",
      "0.9914\n",
      "0.9921\n",
      "0.9927\n",
      "0.9934\n",
      "0.994\n",
      "0.9947\n",
      "0.9954\n",
      "0.996\n",
      "0.9967\n",
      "0.9974\n",
      "0.998\n",
      "0.9987\n",
      "0.9993\n"
     ]
    }
   ],
   "source": [
    "example_dict = {'Fluency': 2, 'Relevance': 3, 'Consistency': 3, 'Coherence': 1}\n",
    "answers_evals = []\n",
    "    \n",
    "for index, row in df.iterrows():\n",
    "    if index < len(answers_evals):\n",
    "        pass\n",
    "    else:\n",
    "        \n",
    "        prompt = f\"\"\" \n",
    "                You will be given one answer written for a question based on a blogpost.\n",
    "\n",
    "                Your task is to rate the answer four metrics.\n",
    "\n",
    "                Please make sure you read and understand these instructions carefully. \n",
    "\n",
    "                Instructions:\n",
    "                    1. Read the question, answers and the blogposts carefully.\n",
    "                    2. Read blog post and identify the issue and solution of the article.\n",
    "                    3. Read the evaluation criterias and ensure you understand them well.\n",
    "                    3. Assess for each evaluation criteria the answer given the question and the blogpost\n",
    "                    4. Assign a score from 1 to 5 for each evaluation criteria.\n",
    "\n",
    "                Evaluation Criterias:\n",
    "                Fluency (1-5): the quality of the answer in terms of grammar, spelling, punctuation, word choice, and sentence structure.\n",
    "                Relevance (1-5) - selection of important content from the source. The answer should include only important information from the source document. Penalize answers which contained redundancies and excess information.\n",
    "                Consistency (1-5) - the factual alignment between the answer and the blogpost. A factually consistent answer contains only statements that are entailed by the blogpost. Penalize summaries that contained hallucinated facts. \n",
    "                Coherence (1-5) - the collective quality of all sentences. The answer should be well-structured and well-organized. The answer should not just be a heap of related information, but should build from sentence to a coherent body of information about a topic.\n",
    "\n",
    "                Example:\n",
    "\n",
    "                Question:\n",
    "                {row['cleaned_questions']}\n",
    "\n",
    "                Answer:\n",
    "                {row['answers']}\n",
    "\n",
    "                Blogpost (in JSON format):\n",
    "                {row['text']}\n",
    "\n",
    "                Evaluation Form (scores ONLY):\n",
    "                - Fluency (1-5):\n",
    "                - Relevance (1-5):\n",
    "                - Consistency (1-5):\n",
    "                - Coherence (1-5):\n",
    "                \n",
    "                Your answer must be in the format of a Python dictionary (and nothing else), e.g: \n",
    "                {example_dict}\n",
    "                \"\"\"\n",
    "        try:\n",
    "            ans = get_gpt(prompt)  \n",
    "            # Initialize dict with metrics from GPT\n",
    "            answer_metrics = ast.literal_eval(ans)\n",
    "            if type(answer_metrics) == dict:\n",
    "                answers_evals.append(answer_metrics)\n",
    "            else:\n",
    "                answers_evals.append(None)\n",
    "        except IndentationError:\n",
    "            answers_evals.append(answer_metrics)\n",
    "\n",
    "        print(round(index / len(df),4))\n",
    "\n",
    "df['answers_evaluations'] = answers_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('2s_llama2_7b.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
